{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "论文实验.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNEZYfN3igtbrv/oBqvJ1Jr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FireDragon00/LaTeX-Template-Cn/blob/master/%E8%AE%BA%E6%96%87%E5%AE%9E%E9%AA%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edf0ttSgcV-T",
        "outputId": "e5598dbb-9e6b-460d-869d-3934f4269301"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install torch\n",
        "!pip install dgl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbU6oIBxmESs",
        "outputId": "d747a12a-a6c1-4f4c-cf1d-dac329bfd5d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: dgl in /usr/local/lib/python3.7/dist-packages (0.6.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.6.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.21.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import model_selection\n",
        "from IPython.display import display, HTML\n",
        "from sklearn.metrics import classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "I1Gq5taPl9Rr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 初始化参数"
      ],
      "metadata": {
        "id": "lHns0nr6mh5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = '/content/drive/MyDrive/researchHub/MAppGraph/mappgraph/data'"
      ],
      "metadata": {
        "id": "IFRKfYZ3l2eM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 20\n",
        "t = 10\n",
        "k = 10  # the number of rows for the output tensor (k = 10, 20)\n",
        "T = 5\n",
        "overlap = 3 # note: overlap depends on T\n",
        "\n",
        "apps = ['diijam', 'baomoi', 'fptplay', 'iQIYI', 'bigo', 'myradio', 'spotify', 'nhaccuatui', 'soundcloud', 'sachnoiapp', \n",
        "        'phim247', 'popskid', 'truyenaudiosachnoiviet', 'vieon', 'voizfm', 'tunefm', 'wetv', 'zingmp3', 'truyenaudio', 'baohay24h',\n",
        "        'freefire', 'among_us', 'azar', 'comico', 'nimotv', 'mangatoon', 'medoctruyen', 'nhacvang', 'noveltoon', 'radiofm',\n",
        "        'vtvgo', 'tivi24h', 'tinder', 'tinmoi24h', 'tivi360', 'tiktok', 'linkedin', 'tiki', 'tinhte', 'lotus', 'tivi247',\n",
        "        'tivi_truyentranh_webtoon', 'tuoitre_online', 'vietnamworks', 'wallstreet_journal', 'cnn_news', 'bbc_news', 'twitter', \n",
        "        'weeboo', 'twitch', 'vnexpress', 'topcv', 'toc_chien', 'wesing', 'hago', 'google_meet', 'dubsmash', 'facebook','hahalolo', \n",
        "        'zalo', 'hello_yo', 'dan_tri', 'zoom', 'wikipedia', 'instagram', 'jobway', 'kaka', 'pinterest', 'quora', 'lazada', 'chess', \n",
        "        'cake', 'mobile_legend', 'co_tuong_online', 'ted', 'telegram', 'starmarker', 'skype', 'soha', 'tango', 'thanhnien', 'snapchat', \n",
        "        'tien_len', 'animal_restaurant', 'bida', 'cho_tot', 'messenger', 'netflix', 'nonolive', 'may', 'podcast_player', 'pubg', \n",
        "        'partying', 'kenh14', 'lienquan_mobile', 'likee_lite', 'reddit', 'sendo', 'shopee', 'the_guardian', 'ola_party']\n",
        "\n",
        "features = ['complete_max', 'complete_min', 'complete_mean', 'complete_mad', 'complete_std', 'complete_var', 'complete_skew',\n",
        "       'complete_kurt', 'complete_pkt_num', 'complete_10per', 'complete_20per', 'complete_30per', 'complete_40per', 'complete_50per', \n",
        "        'complete_60per', 'complete_70per', 'complete_80per', 'complete_90per', 'out_max', 'out_min', 'out_mean', 'out_mad', 'out_std',\n",
        "        'out_var', 'out_skew', 'out_kurt', 'out_pkt_num', 'out_10per', 'out_20per', 'out_30per', 'out_40per', 'out_50per', 'out_60per',\n",
        "        'out_70per', 'out_80per', 'out_90per', 'in_max', 'in_min', 'in_mean', 'in_mad', 'in_std', 'in_var', 'in_skew', 'in_kurt', \n",
        "        'in_pkt_num', 'in_10per', 'in_20per', 'in_30per', 'in_40per', 'in_50per', 'in_60per', 'in_70per', 'in_80per', 'in_90per', \n",
        "        'protocol', 'flows_num', 'flow_length_mean', 'flow_pkt_num_mean', 'flow_duration_mean', 'ip1', 'ip2', 'ip3', 'ip4'\n",
        "       ]"
      ],
      "metadata": {
        "id": "7hEPIiKJfvGa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_graphs_folder = os.path.join(root_path, '%d_%d/train_graphs/N%d/t%d'%(T, overlap, N, t))\n",
        "test_graphs_folder = os.path.join(root_path, '%d_%d/test_graphs/N%d/t%d'%(T, overlap, N, t))"
      ],
      "metadata": {
        "id": "UQ5sCqQtmbJ3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 从一个app文件夹中加载图"
      ],
      "metadata": {
        "id": "SRbdQDawmmy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import dgl\n",
        "\n",
        "'''\n",
        "Load graphs for one app\n",
        "Input: app and folder that contains graphs of the app\n",
        "Output: List of graphs (StellarGraph objects) and List of labels\n",
        "'''\n",
        "\n",
        "\n",
        "def graphs_one_app(app, graphs_folder):\n",
        "\tgraphs = []\n",
        "\n",
        "\tapp_graph_folder = os.path.join(graphs_folder, app)\n",
        "\tfeatures_path = os.path.join(app_graph_folder, 'features.csv')\n",
        "\tweights_path = os.path.join(app_graph_folder, 'weights.csv')\n",
        "\n",
        "\tfeatures_df = pd.read_csv(features_path, index_col=0)\n",
        "\tweights_df = pd.read_csv(weights_path, index_col=0)\n",
        "\n",
        "\tgraph_num = features_df['graph_id'].iloc[-1]\n",
        "\t# loop over all graphs of the app\n",
        "\tfor i in range(1, graph_num + 1):\n",
        "\t\tfeature_df = features_df[features_df['graph_id'] == i]\n",
        "\t\tfeature_df = feature_df[['IP_port'] + features + ['graph_id']]\n",
        "\t\tweight_df = weights_df[weights_df['graph_id'] == i]\n",
        "\n",
        "\t\t# drop graph_id column\n",
        "\t\tfeature_df = feature_df.drop(['graph_id'], axis=1)\n",
        "\t\tweight_df = weight_df.drop(['graph_id'], axis=1)\n",
        "\t\n",
        "\t\t# ip_port to node_id\n",
        "\t\tip_port = list(pd.concat([weight_df['source'], weight_df['target']]).value_counts().index)\n",
        "\t\tnode_id = [i for i in range(len(ip_port))]\n",
        "\n",
        "\t\tweight_df = weight_df.replace(ip_port,node_id)\n",
        "\t\tfeature_df = feature_df.replace(ip_port, node_id).sort_values(by=['IP_port']).set_index('IP_port')\n",
        "\t\n",
        "\t\t# .reset_index(drop=True)\n",
        "\n",
        "\n",
        "\t\tif weight_df.shape[0] > 0:\n",
        "\t\t\t\n",
        "\t\t\tu, v = torch.tensor(pd.concat([weight_df['source'],weight_df['target']]).values.astype('int32')),\\\n",
        "\t\t\ttorch.tensor(pd.concat([weight_df['target'],weight_df['source']]).values.astype('int32'))\n",
        "\t\t\t# print(u)\n",
        "\t\t\tg = dgl.graph((u, v))\n",
        "\t \n",
        "\t\t\tweights = torch.tensor(pd.concat([weight_df['weight'],weight_df['weight']]).values.astype('float32'))\n",
        "\t\t\tg.edata['w'] = weights\n",
        "\n",
        "\t\t\tfeats = torch.tensor(np.array(feature_df.values).astype('float32'))\n",
        "\t\t\tg.ndata['attr'] = feats\n",
        "\t\t\tgraphs.append(g)\n",
        "\t\t\t# print(g)\n",
        "\n",
        "\treturn graphs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvOZ5A98mrQ5",
        "outputId": "f25ea968-e50b-401d-f61e-19cfedf0a80b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using backend: pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 从所有APP中加载图"
      ],
      "metadata": {
        "id": "reAJSMbhnqfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Load all graphs\n",
        "Input: folder that contains graphs\n",
        "Output: List of graphs (StellarGraph objects), List of graph_labels (dummy values) and List of labels (names of app)\n",
        "'''\n",
        "\n",
        "\n",
        "def generate_graphs(graphs_folder):\n",
        "\t# build a list of graphs and labels: note that only apply for more than 2 classes\n",
        "\tli = []\n",
        "\tlabels = []\n",
        "\tidx = 0\n",
        "\n",
        "\tfor app in apps:\n",
        "\t\t\n",
        "\t\tprint('Loading {} ... {}/{}'.format(app, idx, len(apps)))\n",
        "\n",
        "\t\tone_app_graphs = graphs_one_app(app, graphs_folder)\n",
        "\t\t# print(len(one_app_graphs))\n",
        "\t\tone_app_labels = [idx for _ in range(len(one_app_graphs))]\n",
        "\t\t# print(len(one_app_labels))\n",
        "\t\tli.extend(one_app_graphs)\n",
        "\t\tlabels.extend(one_app_labels)\n",
        "\t\tidx += 1\n",
        "\n",
        "\tgraph_labels = labels\n",
        "\tgraphs = li\n",
        "\n",
        "\tprint('...............................................................')\n",
        "\n",
        "\treturn graphs, graph_labels"
      ],
      "metadata": {
        "id": "UpmGurYKmviR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_graphs, train_graph_labels = generate_graphs(train_graphs_folder)\n",
        "test_graphs, test_graph_labels = generate_graphs(test_graphs_folder)\n",
        "train_size = len(train_graphs)"
      ],
      "metadata": {
        "id": "e_XznTPqn4I1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_graph_labels))\n",
        "print(len(test_graph_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDFqVRSLsokE",
        "outputId": "8bfe9222-6e24-4bd6-eb3d-0764fa914b20"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66236\n",
            "16561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.data.utils import save_graphs\n",
        "\n",
        "train_labels = {\"labels\": torch.tensor(train_graph_labels)}\n",
        "test_labels = {\"labels\": torch.tensor(test_graph_labels)}\n",
        "\n",
        "save_graphs(\"/content/drive/MyDrive/train_graphs.bin\", train_graphs, train_labels)\n",
        "save_graphs(\"/content/drive/MyDrive/test_graphs.bin\", test_graphs, test_labels)\n",
        "# graphs, label = load_graphs('sample/train_graphs.bin')\n",
        "# print(type(graphs), type(label))\n",
        "# print(graphs[0])"
      ],
      "metadata": {
        "id": "trrVCgQk4aBU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.data import DGLDataset\n",
        "from dgl.data.utils import load_graphs\n",
        "\n",
        "# g, l = load_graphs('sample/train_graphs.bin')\n",
        "\n",
        "class Traindataset(DGLDataset):\n",
        "  _url = 'http://deepchem.io.s3-website-us-west-1.amazonaws.com/datasets/qm7b.mat'\n",
        "  _sha1_str = '4102c744bb9d6fd7b40ac67a300e49cd87e28392'\n",
        "\n",
        "  def __init__(self, raw_dir=None, force_reload=False, verbose=False):\n",
        "    super().__init__(name='qm7b',\n",
        "            url=self._url,\n",
        "            raw_dir=raw_dir,\n",
        "            force_reload=force_reload,\n",
        "            verbose=verbose)\n",
        "\n",
        "  def process(self):\n",
        "    # 将数据处理为图列表和标签列表\n",
        "    self.graphs, label_dict = load_graphs('sample/train_graphs.bin')\n",
        "    self.label = label_dict['train_labels']\n",
        "    # self.graphs, self.label = train_graphs, train_graph_labels\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    \"\"\" 通过idx获取对应的图和标签\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    idx : int\n",
        "        Item index\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    (dgl.DGLGraph, Tensor)\n",
        "    \"\"\"\n",
        "    return self.graphs[idx], self.label[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    \"\"\"数据集中图的数量\"\"\"\n",
        "    return len(self.graphs)\n",
        "  \n",
        "  @property\n",
        "  def num_labels(self):\n",
        "    return 101"
      ],
      "metadata": {
        "id": "02srrMOysuMs"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.dataloading import GraphDataLoader\n",
        "\n",
        "dataset = Traindataset()\n",
        "dataloader = GraphDataLoader(\n",
        "  dataset,\n",
        "  batch_size=1024,\n",
        "  drop_last=False,\n",
        "  shuffle=True)\n",
        "print(dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfg0TrMZs3u_",
        "outputId": "475c1bf5-5c82-4f6a-8c41-83d62a75dc96"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Graph(num_nodes=3, num_edges=6,\n",
            "      ndata_schemes={'attr': Scheme(shape=(63,), dtype=torch.float32)}\n",
            "      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)}), tensor(0))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "import torch\n",
        "import dgl.nn.pytorch as dglnn\n",
        "import torch.nn as nn\n",
        "from dgl.nn.pytorch.conv import GATConv\n",
        "from dgl.nn.pytorch.conv import DenseGraphConv\n",
        "from dgl.nn.pytorch.glob import SortPooling\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self, in_dim, hidden_dim, n_classes, batch_size, num_graph):\n",
        "    super(Classifier, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.num_graph = num_graph\n",
        "    self.gat1 = GATConv(in_dim, hidden_dim, 5)\n",
        "    self.gat2 = GATConv(hidden_dim*5, hidden_dim, 5)\n",
        "    \n",
        "    #l2_out: torch.Size([3371, 5, 20])==>l2_flatten: torch.Size([3371, 100])\n",
        "    self.sortpooling = SortPooling(k=16)\n",
        "    #sortpool: torch.Size([1024, 1600])\n",
        "    self.conv1D_1 = nn.Conv1d(1, 128, kernel_size=3)\n",
        "    self.maxpooling = nn.MaxPool1d(3)\n",
        "    self.conv1D_2 = nn.Conv1d(128, 256, kernel_size=2)\n",
        "    self.classify = nn.Linear(256*531, n_classes)\n",
        "\n",
        "  def forward(self, g, h):\n",
        "    # print('raw_shape:',h.size())\n",
        "    # GATConv\n",
        "    h = F.relu(self.gat1(g, h))\n",
        "    # print('l1_out:', h.size())\n",
        "    h = h.flatten(1)\n",
        "    # print('l1_flatten:', h.size())\n",
        "    h = F.relu(self.gat2(g, h))\n",
        "    # print('l2_out:', h.size())\n",
        "    h = h.flatten(1)\n",
        "    # print('l2_flatten:', h.size())\n",
        "\n",
        "    # sortpool——图池化\n",
        "    h = self.sortpooling(g, h)\n",
        "    # print('pool1:', h.size())\n",
        "    try:\n",
        "      h = h.view(1024, 1, 1600)\n",
        "    except:\n",
        "      x = self.num_graph % self.batch_size\n",
        "      h = h.view(x , 1, 1600)\n",
        "    # print('view:', h.size())\n",
        "    h = self.conv1D_1(h)\n",
        "    # print('conv1:', h.size())\n",
        "    h = self.maxpooling(h)\n",
        "    # print('pool2:', h.size())\n",
        "    h = self.conv1D_2(h)\n",
        "    # print('conv2:', h.size())\n",
        "    h = F.relu(h.flatten(1))\n",
        "    h = F.dropout(h)\n",
        "    with g.local_scope():\n",
        "        return self.classify(h)"
      ],
      "metadata": {
        "id": "PFAr-_8gsyef"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Classifier(63, 20, 101, 1024, 66236)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "model.train()\n",
        "\n",
        "epoch_losses = []\n",
        "for epoch in range(50):\n",
        "  epoch_loss = 0\n",
        "  i = 0\n",
        "  for batched_graph, labels in dataloader:\n",
        "      feats = batched_graph.ndata['attr']\n",
        "      logits = model(batched_graph, feats)\n",
        "      # print(logits.size())\n",
        "      loss = F.cross_entropy(logits, labels)\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      epoch_loss += loss.detach().item()\n",
        "      i += 1\n",
        "  epoch_loss /= (i+1)\n",
        "  print('Epoch {}, loss {:.4f}'.format(epoch, epoch_loss))\n",
        "  epoch_losses.append(epoch_loss)"
      ],
      "metadata": {
        "id": "szo2fqUDs6mJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}